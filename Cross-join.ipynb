{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 87.0589747428894 seconds ---\n",
      "   Restaurant Id        Restaurant Name Hotel Id  \\\n",
      "0            365          Coco's Bakery      446   \n",
      "1            365          Coco's Bakery       73   \n",
      "2            524        Jack in the Box      309   \n",
      "3            524        Jack in the Box       48   \n",
      "4            420         Royal Hawaiian      220   \n",
      "..           ...                    ...      ...   \n",
      "87           474        Jack in the Box      132   \n",
      "88           104  The Buckeye Roadhouse       70   \n",
      "89           122            Dairy Queen      495   \n",
      "90           506        Jack in the Box      337   \n",
      "91           201              Carl's Jr      451   \n",
      "\n",
      "                       Hotel Name  Distance  \n",
      "0      Best Western Americana Inn      0.02  \n",
      "1        America's Best Value Inn      0.31  \n",
      "2                    Best Western      0.36  \n",
      "3        America's Best Value Inn      0.27  \n",
      "4                 Arabella Laguna      0.49  \n",
      "..                            ...       ...  \n",
      "87       America's Best Value Inn      0.33  \n",
      "88       America's Best Value Inn      0.09  \n",
      "89      Best Western Heritage Inn      0.39  \n",
      "90                     Budget Inn      0.45  \n",
      "91  Best Western Cameron Park Inn      0.16  \n",
      "\n",
      "[92 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "import collections\n",
    "from math import sin, cos, sqrt, atan2, radians, asin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import row_number, monotonically_increasing_id\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, radians, asin, sin, sqrt, cos\n",
    "from haversine import haversine\n",
    "import time\n",
    "\n",
    "# Create a SparkSession (Note, the config section is only for Windows!)\n",
    "spark = SparkSession.builder.config(\"spark.sql.warehouse.dir\", \"data\").appName(\"SparkSQL\").getOrCreate()\n",
    "\n",
    "\n",
    "rdd = sc.textFile(\"hotels-exmpl.txt\")\n",
    "rdd1 = rdd.map(lambda x : (x.split(\"|\")[0], x.split(\"|\")[1], x.split(\"|\")[4], x.split(\"|\")[5]))\n",
    "df1 = rdd1.toDF()\n",
    "df2 = df1.selectExpr(\"_1 as _id\", \"_2 as name\",\"_3 as lat\", \"_4 as lon\")\n",
    "df3 = df2.withColumn(\"dataset_id\", lit(\"B\"))\n",
    "\n",
    "rdd2 = sc.textFile(\"restaurants-exmpl.txt\")\n",
    "rdd3 = rdd2.map(lambda x : (x.split(\"|\")[0], x.split(\"|\")[1], x.split(\"|\")[3], x.split(\"|\")[4]))\n",
    "df4 = rdd3.toDF()\n",
    "df5 = df4.selectExpr(\"_1 as _id\", \"_2 as name\",\"_3 as lat\", \"_4 as lon\")\n",
    "df6 = df5.withColumn(\"dataset_id\", lit(\"A\"))\n",
    "\n",
    "df_concat = df3.union(df6)\n",
    "df_concat1 = df_concat.orderBy(df_concat[\"lat\"].asc())\n",
    "dataset = df_concat1.withColumn(\"increas_id\",row_number().over(Window.orderBy(monotonically_increasing_id()))-1)\n",
    "dataset1 = dataset.withColumn(\"partition\",(col(\"increas_id\")/260).cast(\"int\"))\n",
    "dataset2 = dataset1.withColumn(\"lat\", dataset[\"lat\"].cast(\"float\"))\n",
    "dataset3 = dataset2.withColumn(\"lon\", dataset[\"lon\"].cast(\"float\"))\n",
    "dataset1_partitioned = dataset3.repartitionByRange(4, col(\"partition\"))\n",
    "#dataset1_partitioned.write.mode(\"overwrite\").csv(\"apotelesmata/results.txt\")\n",
    "\n",
    "start_time = time.time() \n",
    "dist = 2\n",
    "final_table = []\n",
    "for x in dataset1_partitioned.collect():\n",
    "    for y in dataset1_partitioned.collect():\n",
    "        if (x[\"dataset_id\"] == \"A\") and (y[\"dataset_id\"] == \"B\"):\n",
    "            restaurant_id = x[0]\n",
    "            restaurant_name = x[1]\n",
    "            restaurant_lat = x[2]\n",
    "            restaurant_lon = x[3]\n",
    "  \n",
    "            max_distance = 0.5  #10\n",
    "            R = 6373.0\n",
    "            hotel_id = y[0]\n",
    "            hotel_name = y[1]\n",
    "            hotel_lat = y[2]\n",
    "            hotel_lon = y[3]\n",
    "            \n",
    "            distance = haversine((restaurant_lat, restaurant_lon),(hotel_lat, hotel_lon))\n",
    "\n",
    "            \n",
    "            if distance <= max_distance:\n",
    "                row = []\n",
    "                row.append(restaurant_id)\n",
    "                row.append(restaurant_name)\n",
    "                row.append(hotel_id)\n",
    "                row.append(hotel_name)\n",
    "                row.append(np.around(distance,2))\n",
    "                final_table.append(row)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) \n",
    "\n",
    "results_DF = pd.DataFrame(final_table,columns=['Restaurant Id', 'Restaurant Name', 'Hotel Id', 'Hotel Name','Distance'])\n",
    "results_DF.count()\n",
    "print(results_DF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
